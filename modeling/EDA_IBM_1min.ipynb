{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA IBM stock 1min ticks\n",
    "\n",
    "## Takeouts -  december 29/2019\n",
    "* The distribution of the difference of the time series has very long tails: see plot. This was expected; still very ugly.\n",
    "* Created a very clean dataset with 'pastValues', 'currentValue', 'futureValue', 'deltaMinutes'. \n",
    "* The precision recall curve that we already have looks quite good: we trained one single time.\n",
    "\n",
    "## Takeouts -  december 30/2019\n",
    "* Plot a precision recall curve with several(monthly/weekly) training batches\n",
    "\n",
    "## To do\n",
    "\n",
    "* There is a delicate issue about rescaling before training that needs to be fixed asap.\n",
    "* Turn the code that produces the 'clean' data set into a more reusable one\n",
    "* The current version of the target is not very realistic.\n",
    "* Need a more elaborated way of looking at histograms: the tails don't let me see anything: those tails are a huge concern.\n",
    "* Look out for sklearn methods to do crossvalidation in our setting: do not reinvent the wheel.\n",
    "\n",
    "## Questions to Jake:\n",
    "* Data provider (currently using sample (adjusted) data from Kibot): he uses polygon\n",
    "* How can I authomatize making orders, is there an api? how does this even work in real life? he mentioned 'efficient frontier'\n",
    "* Cost per order (0.5 cents per share or 2 dollars per trade)\n",
    "* Latency issues to be aware of.\n",
    "* How/at what point can we know if we are `moving the market` too much? In the afternoon there is very little volume.\n",
    "\n",
    "\n",
    "## Notes from Jake\n",
    "* Tick data might be more useful for quant analysis.\n",
    "* polygon.io source of data.\n",
    "* thinkorswim.com: 2 dollars per trade, \n",
    "* interactivebrokers : half a cent per share.\n",
    "* kelly criterion?\n",
    "* ibridgepy ... take quantopian to real life.\n",
    "* zipline - quantopian type of thing.\n",
    "* efficient frontier. for blending the strategies.\n",
    "* kygo: his thing.\n",
    "* Use quantopian!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lduque/Desktop/MyProjects/moneyManager\n"
     ]
    }
   ],
   "source": [
    "cd ~/Desktop/MyProjects/moneyManager/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling.dataSetUtilities import createTrainingDataSet\n",
    "from modeling.generatePipeline import generatePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve \n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier ## might not be necessary in the future?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Date', 'Time', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "df = pd.read_csv('data/sampleKibotData/minuteIntraday/IBM_adjusted.txt', header=None, names=names, nrows=2000)\n",
    "df['DateTime']= pd.to_datetime((df.Date+' '+df.Time),infer_datetime_format=True) \n",
    "df = df.drop(columns=['Date', 'Time'])\n",
    "df = df.set_index('DateTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()\n",
    "#df.Open.plot(figsize=(15,5), title='IBM stock');\n",
    "#df.index.map(lambda x: x.year).value_counts().sort_index().plot.bar(figsize=(15, 5), title='ticks per year');\n",
    "#df.Open.diff().plot.hist(bins=200, figsize=(15,5), title= 'distribution of the differential');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg= createTrainingDataSet(df, numPastMins=3, numFutureMins=3)\n",
    "X = dg.copy()\n",
    "y = X.pop('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = generatePipeline()\n",
    "T = pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A precision recall-curve with only one training split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporal split of train/test\n",
    "trainPercentage = 20\n",
    "testBegins = (len(X)*trainPercentage)//100\n",
    "Xtrain, ytrain = X[:testBegins], y[:testBegins]\n",
    "Xtest, ytest = X[testBegins:], y[testBegins:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'min_samples_leaf' : [10, 20, 100],\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'n_estimators': [10, 20, 100],   \n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "regr = RandomForestClassifier(class_weight='balanced')\n",
    "grid = GridSearchCV(regr, parameters, cv=2, scoring='average_precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(Xtrain, ytrain)\n",
    "model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_rate = sum(ytest)/len(ytest)\n",
    "ypredicted=model.predict_proba(Xtest)[:,1]\n",
    "average_precision = average_precision_score(ytest, ypredicted)\n",
    "disp = plot_precision_recall_curve(model, Xtest, ytest)\n",
    "disp.ax_.set_title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))\n",
    "plt.plot([0, 1], [base_rate, base_rate]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A precision-recall curve with multiple training batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([dg.pastValues.apply(lambda x:pd.Series(x)), dg.currentValue, dg.target], axis=1)\n",
    "firstTimeStamp=X.index[0]\n",
    "first_day = datetime(firstTimeStamp.year, firstTimeStamp.month, firstTimeStamp.day)\n",
    "X['week']=pd.Series(X.index).apply(lambda x: (datetime(x.year, x.month, x.day)-first_day).days//7).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice that for the week zero we wont have a model.\n",
    "trainSets = [X[X.week==w] for w in X.week.unique()]\n",
    "trainTestBarches = [(None, None, None, None)]+[(trainSets[i].drop(columns='target'),trainSets[i].target,trainSets[i+1].drop(columns='target'),trainSets[i+1].target) for i in range(len(trainSets)-1)]\n",
    "models = [None] + [GridSearchCV(regr, parameters, cv=2, scoring='average_precision') for _ in range(len(trainSets)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, ytrain, Xtest, ytest = trainTestBarches[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain # notice: week should not be in the model, but its ok for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(models)):\n",
    "    print(i)\n",
    "    Xtrain, ytrain, Xtest, ytest = trainTestBarches[i]\n",
    "    models[i].fit(Xtrain.div(Xtrain.currentValue, axis=0), ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is worth saving somewhere !\n",
    "def indexedModelEvaluation(x):\n",
    "    row = x.copy()\n",
    "    week = row['week']\n",
    "    row = row.drop('target')\n",
    "    row = [list(row/row.currentValue)]\n",
    "    model = models[week]\n",
    "    return np.nan if model==None else model.predict_proba(row)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredicted = X.apply(indexedModelEvaluation,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['predicted']=ypredicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = X[['predicted', 'target']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = dh[dh.predicted.notna()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest = dh.target\n",
    "ypredicted = dh.predicted\n",
    "base_rate = sum(ytest)/len(ytest)\n",
    "average_precision = average_precision_score(ytest, ypredicted)\n",
    "precision, recall, _ = precision_recall_curve(ytest, ypredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(recall, precision)\n",
    "plt.plot([0, 1], [base_rate, base_rate]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
