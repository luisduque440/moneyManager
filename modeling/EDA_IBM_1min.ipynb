{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA IBM stock 1min ticks\n",
    "\n",
    "## Takeouts -  december 29/2019\n",
    "* The distribution of the difference of the time series has very long tails: see plot. This was expected; still very ugly.\n",
    "* Created a very clean dataset with 'pastValues', 'currentValue', 'futureValue', 'deltaMinutes'. \n",
    "* The precision recall curve that we already have looks quite good: we trained one single time.\n",
    "\n",
    "## Takeouts -  december 30/2019\n",
    "* Plot a precision recall curve with several(monthly/weekly) training batches\n",
    "\n",
    "## To do\n",
    "\n",
    "* There is a delicate issue about rescaling before training that needs to be fixed asap.\n",
    "* Turn the code that produces the 'clean' data set into a more reusable one\n",
    "* The current version of the target is not very realistic.\n",
    "* Need a more elaborated way of looking at histograms: the tails don't let me see anything: those tails are a huge concern.\n",
    "* Look out for sklearn methods to do crossvalidation in our setting: do not reinvent the wheel.\n",
    "\n",
    "## Questions to Jake:\n",
    "* Data provider (currently using sample (adjusted) data from Kibot): he uses polygon\n",
    "* How can I authomatize making orders, is there an api? how does this even work in real life? he mentioned 'efficient frontier'\n",
    "* Cost per order (0.5 cents per share or 2 dollars per trade)\n",
    "* Latency issues to be aware of.\n",
    "* How/at what point can we know if we are `moving the market` too much? In the afternoon there is very little volume.\n",
    "\n",
    "\n",
    "## Notes from Jake\n",
    "* Tick data might be more useful for quant analysis.\n",
    "* polygon.io source of data.\n",
    "* thinkorswim.com: 2 dollars per trade, \n",
    "* interactivebrokers : half a cent per share.\n",
    "* kelly criterion?\n",
    "* ibridgepy ... take quantopian to real life.\n",
    "* zipline - quantopian type of thing.\n",
    "* efficient frontier. for blending the strategies.\n",
    "* kygo: his thing.\n",
    "* Use quantopian!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lduque/Desktop/MyProjects/moneyManager\n"
     ]
    }
   ],
   "source": [
    "cd ~/Desktop/MyProjects/moneyManager/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only loading some rows\n",
    "names = ['Date', 'Time', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "df = pd.read_csv('data/sampleKibotData/minuteIntraday/IBM_adjusted.txt', header=None, names=names, nrows=2000)\n",
    "df['DateTime'] = df.Date+' '+df.Time\n",
    "df.DateTime = pd.to_datetime(df.DateTime,infer_datetime_format=True) \n",
    "ds = df.drop(columns=['Date', 'Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>DateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.69</td>\n",
       "      <td>33.69</td>\n",
       "      <td>33.69</td>\n",
       "      <td>33.69</td>\n",
       "      <td>207820</td>\n",
       "      <td>1998-01-02 09:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.65</td>\n",
       "      <td>33.69</td>\n",
       "      <td>33.65</td>\n",
       "      <td>33.65</td>\n",
       "      <td>33499</td>\n",
       "      <td>1998-01-02 09:31:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.67</td>\n",
       "      <td>33.69</td>\n",
       "      <td>33.65</td>\n",
       "      <td>33.69</td>\n",
       "      <td>41254</td>\n",
       "      <td>1998-01-02 09:32:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.67</td>\n",
       "      <td>33.69</td>\n",
       "      <td>33.65</td>\n",
       "      <td>33.65</td>\n",
       "      <td>52110</td>\n",
       "      <td>1998-01-02 09:33:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.65</td>\n",
       "      <td>33.69</td>\n",
       "      <td>33.65</td>\n",
       "      <td>33.65</td>\n",
       "      <td>14892</td>\n",
       "      <td>1998-01-02 09:34:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>33.19</td>\n",
       "      <td>33.21</td>\n",
       "      <td>33.17</td>\n",
       "      <td>33.17</td>\n",
       "      <td>29467</td>\n",
       "      <td>1998-01-09 10:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>33.17</td>\n",
       "      <td>33.17</td>\n",
       "      <td>33.15</td>\n",
       "      <td>33.15</td>\n",
       "      <td>64210</td>\n",
       "      <td>1998-01-09 10:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>33.15</td>\n",
       "      <td>33.17</td>\n",
       "      <td>33.15</td>\n",
       "      <td>33.17</td>\n",
       "      <td>19541</td>\n",
       "      <td>1998-01-09 10:51:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>33.17</td>\n",
       "      <td>33.17</td>\n",
       "      <td>33.15</td>\n",
       "      <td>33.15</td>\n",
       "      <td>3722</td>\n",
       "      <td>1998-01-09 10:52:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>33.13</td>\n",
       "      <td>33.17</td>\n",
       "      <td>33.07</td>\n",
       "      <td>33.07</td>\n",
       "      <td>157261</td>\n",
       "      <td>1998-01-09 10:53:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open   High    Low  Close  Volume            DateTime\n",
       "0     33.69  33.69  33.69  33.69  207820 1998-01-02 09:30:00\n",
       "1     33.65  33.69  33.65  33.65   33499 1998-01-02 09:31:00\n",
       "2     33.67  33.69  33.65  33.69   41254 1998-01-02 09:32:00\n",
       "3     33.67  33.69  33.65  33.65   52110 1998-01-02 09:33:00\n",
       "4     33.65  33.69  33.65  33.65   14892 1998-01-02 09:34:00\n",
       "...     ...    ...    ...    ...     ...                 ...\n",
       "1995  33.19  33.21  33.17  33.17   29467 1998-01-09 10:49:00\n",
       "1996  33.17  33.17  33.15  33.15   64210 1998-01-09 10:50:00\n",
       "1997  33.15  33.17  33.15  33.17   19541 1998-01-09 10:51:00\n",
       "1998  33.17  33.17  33.15  33.15    3722 1998-01-09 10:52:00\n",
       "1999  33.13  33.17  33.07  33.07  157261 1998-01-09 10:53:00\n",
       "\n",
       "[2000 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.Open.plot(figsize=(15,5), title='IBM stock');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.DateTime.apply(lambda x: x.year).value_counts().sort_index().plot.bar(figsize=(15, 5), title='ticks per year');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.Open.diff().plot.hist(bins=200, figsize=(15,5), title= 'distribution of the differential');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivotTimeSeries(ds):\n",
    "    pastWindow = 5\n",
    "    futureWindow = 10\n",
    "    \n",
    "    dsTimeStamp = ds.DateTime\n",
    "    pastLow = pd.concat([ds.Low.shift(i) for i in range(pastWindow, 0, -1)], axis=1).apply(lambda x: list(x), axis=1)\n",
    "    pastHigh = pd.concat([ds.High.shift(i) for i in range(pastWindow, 0, -1)], axis=1).apply(lambda x: list(x), axis=1)\n",
    "    pastVolume = pd.concat([ds.Volume.shift(i) for i in range(pastWindow, 0, -1)], axis=1).apply(lambda x: list(x), axis=1)\n",
    "    \n",
    "    currentValue = ds.Close\n",
    "    currentVolume = ds.Volume\n",
    "    \n",
    "    futureHigh = pd.concat([ds.High.shift(i) for i in range(-1, -futureWindow-1, -1)], axis=1).apply(lambda x: max(list(x)), axis=1)\n",
    "    deltaMinutes = (ds.DateTime.shift(-futureWindow) - ds.DateTime.shift(pastWindow)).apply(lambda x: x.seconds)//60\n",
    "    \n",
    "    dg = pd.concat([dsTimeStamp, pastLow, pastHigh, pastVolume, currentValue, currentVolume, futureHigh, deltaMinutes], axis=1)\n",
    "    dg.columns = ['DateTime', 'pastLow', 'pastHigh', 'pastVolume', 'currentValue', 'currentVolume', 'futureHigh', 'deltaMinutes']\n",
    "    dg['target']= dg.futureHigh>dg.currentValue\n",
    "    dg = dg.drop(columns='futureHigh')\n",
    "    dg = dg[dg.deltaMinutes==(pastWindow+futureWindow)].drop(columns='deltaMinutes')\n",
    "    dg = dg.set_index('DateTime')\n",
    "    return dg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produceFeatures(dg):\n",
    "    # rescale pastLow, pastHigh (using currentValue), remove currentValue\n",
    "    scaledPastLow = dg.apply(lambda x: np.array(x.pastLow)/x.currentValue, axis=1)\n",
    "    scaledPastHigh = dg.apply(lambda x: np.array(x.pastHigh)/x.currentValue, axis=1)\n",
    "    scaledPastVolume = dg.apply(lambda x: np.array(x.currentVolume)/x.currentVolume, axis=1)\n",
    "    \n",
    "    pastLowFeatures = scaledPastLow.apply(listToFeatures)\n",
    "    pastHighFeatures = scaledPastLow.apply(listToFeatures)\n",
    "    pastVolumeFeatures = scaledPastLow.apply(listToFeatures)\n",
    "    \n",
    "    W = (pastLowFeatures + pastHighFeatures + pastVolumeFeatures).apply(lambda x: pd.Series(x))\n",
    "    \n",
    "    # consider rescaling only at the very end?\n",
    "    # rescale pastVolume (using currentVolume) remove currentVolume\n",
    "    return W\n",
    "    \n",
    "    \n",
    "def listToFeatures(x):\n",
    "    L = list(x)\n",
    "    features = [max(L), min(L), np.mean(L), np.std(L), np.median(L)]\n",
    "    return features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produceFeatures(dg).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [3,4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(L)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = pivotTimeSeries(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg.target.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([dg.pastValues.apply(lambda x:pd.Series(x)), dg.currentValue, dg.target], axis=1)\n",
    "y = X.pop('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescaling the dataframe\n",
    "X = X.div(X.currentValue, axis=0)\n",
    "X.drop(columns='currentValue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A precision recall-curve with only one training split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporal split of train/test\n",
    "trainPercentage = 20\n",
    "testBegins = (len(X)*trainPercentage)//100\n",
    "Xtrain, ytrain = X[:testBegins], y[:testBegins]\n",
    "Xtest, ytest = X[testBegins:], y[testBegins:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'min_samples_leaf' : [10, 20, 100],\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'n_estimators': [10, 20, 100],   \n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "regr = RandomForestClassifier(class_weight='balanced')\n",
    "grid = GridSearchCV(regr, parameters, cv=2, scoring='average_precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(Xtrain, ytrain)\n",
    "model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_rate = sum(ytest)/len(ytest)\n",
    "ypredicted=model.predict_proba(Xtest)[:,1]\n",
    "average_precision = average_precision_score(ytest, ypredicted)\n",
    "disp = plot_precision_recall_curve(model, Xtest, ytest)\n",
    "disp.ax_.set_title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))\n",
    "plt.plot([0, 1], [base_rate, base_rate]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A precision-recall curve with multiple training batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([dg.pastValues.apply(lambda x:pd.Series(x)), dg.currentValue, dg.target], axis=1)\n",
    "firstTimeStamp=X.index[0]\n",
    "first_day = datetime(firstTimeStamp.year, firstTimeStamp.month, firstTimeStamp.day)\n",
    "X['week']=pd.Series(X.index).apply(lambda x: (datetime(x.year, x.month, x.day)-first_day).days//7).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice that for the week zero we wont have a model.\n",
    "trainSets = [X[X.week==w] for w in X.week.unique()]\n",
    "trainTestBarches = [(None, None, None, None)]+[(trainSets[i].drop(columns='target'),trainSets[i].target,trainSets[i+1].drop(columns='target'),trainSets[i+1].target) for i in range(len(trainSets)-1)]\n",
    "models = [None] + [GridSearchCV(regr, parameters, cv=2, scoring='average_precision') for _ in range(len(trainSets)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, ytrain, Xtest, ytest = trainTestBarches[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain # notice: week should not be in the model, but its ok for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(models)):\n",
    "    print(i)\n",
    "    Xtrain, ytrain, Xtest, ytest = trainTestBarches[i]\n",
    "    models[i].fit(Xtrain.div(Xtrain.currentValue, axis=0), ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is worth saving somewhere !\n",
    "def indexedModelEvaluation(x):\n",
    "    row = x.copy()\n",
    "    week = row['week']\n",
    "    row = row.drop('target')\n",
    "    row = [list(row/row.currentValue)]\n",
    "    model = models[week]\n",
    "    return np.nan if model==None else model.predict_proba(row)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredicted = X.apply(indexedModelEvaluation,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['predicted']=ypredicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = X[['predicted', 'target']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = dh[dh.predicted.notna()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest = dh.target\n",
    "ypredicted = dh.predicted\n",
    "base_rate = sum(ytest)/len(ytest)\n",
    "average_precision = average_precision_score(ytest, ypredicted)\n",
    "precision, recall, _ = precision_recall_curve(ytest, ypredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(recall, precision)\n",
    "plt.plot([0, 1], [base_rate, base_rate]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
