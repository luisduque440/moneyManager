{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA IBM stock 1min ticks\n",
    "\n",
    "## Takeouts -  december 29/2019\n",
    "* The distribution of the difference of the time series has very long tails: see plot. This was expected; still very ugly.\n",
    "* Created a very clean dataset with 'pastValues', 'currentValue', 'futureValue', 'deltaMinutes'. \n",
    "* The precision recall curve that we already have looks quite good: we trained one single time.\n",
    "\n",
    "## Takeouts -  december 29/2019\n",
    "\n",
    "## To do\n",
    "* Plot a precision recall curve in which we do several (monthly/weekly) training bashes.\n",
    "* Turn the code that produces the 'clean' data set into a more reusable one\n",
    "* The current version of the target is not very realistic.\n",
    "* Need a more elaborated way of looking at histograms: the tails don't let me see anything: those tails are a huge concern.\n",
    "* Look out for sklearn methods to do crossvalidation in our setting: do not reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/Desktop/MyProjects/moneyManager/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import plot_precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only loading some rows\n",
    "names = ['Date', 'Time', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "df = pd.read_csv('data/sampleKibotData/minuteIntraday/IBM_adjusted.txt', header=None, names=names)\n",
    "df['DateTime'] = df.Date+' '+df.Time\n",
    "df.DateTime = pd.to_datetime(df.DateTime,infer_datetime_format=True) \n",
    "ds = df[['DateTime', 'Open']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.set_index('DateTime').plot(figsize=(15,5), title='IBM stock');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.DateTime.apply(lambda x: x.year).value_counts().sort_index().plot.bar(figsize=(15, 5), title='ticks per year');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.Open.diff().plot.hist(bins=200, figsize=(15,5), title= 'distribution of the differential');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSize = 5\n",
    "dsPast = pd.concat([ds.Open.shift(i) for i in range(windowSize, 0, -1)], axis=1).apply(lambda x: list(x), axis=1)\n",
    "dsPresent = ds.Open\n",
    "dsFuture = pd.concat([ds.Open.shift(i) for i in range(-1, -windowSize-1, -1)], axis=1).apply(lambda x: list(x), axis=1)\n",
    "deltaMinutes = (ds.DateTime.shift(-windowSize) - ds.DateTime.shift(windowSize)).apply(lambda x: x.seconds)//60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = pd.concat([ds.DateTime, dsPast, dsPresent, dsFuture, deltaMinutes], axis=1)\n",
    "dg.columns = ['DateTime', 'pastValues', 'currentValue', 'futureValue', 'deltaMinutes']\n",
    "dg = dg.set_index('DateTime')\n",
    "dg['target']=(dg.futureValue.apply(lambda x: max(x))>dg.currentValue)\n",
    "dg=dg[dg.deltaMinutes==10.0]\n",
    "dg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg.target.value_counts().plot.bar(title='distribution of (price is increasing in the near future)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([dg.pastValues.apply(lambda x:pd.Series(x)), dg.currentValue, dg.target], axis=1)\n",
    "y = X.pop('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescaling the dataframe\n",
    "X = X.div(X.currentValue, axis=0)\n",
    "X.drop(columns='currentValue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporal split of train/test\n",
    "trainPercentage = 20\n",
    "testBegins = (len(X)*trainPercentage)//100\n",
    "Xtrain, ytrain = X[:testBegins], y[:testBegins]\n",
    "Xtest, ytest = X[testBegins:], y[testBegins:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "parameters = {\n",
    "    'min_samples_leaf' : [100, 1000, 2000],\n",
    "    'max_depth': [50,100, 200],\n",
    "    'n_estimators': [100, 200],   \n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "regr = RandomForestClassifier(class_weight='balanced')\n",
    "grid = GridSearchCV(regr, parameters, cv=3, scoring='average_precision', return_train_score=True)\n",
    "grid.fit(Xtrain, ytrain)\n",
    "model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = list(ytest)\n",
    "ypredicted=model.predict_proba(Xtest)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_rate = sum(ytest)/len(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision = average_precision_score(ytest, ypredicted)\n",
    "disp = plot_precision_recall_curve(model, Xtest, ytest)\n",
    "disp.ax_.set_title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))\n",
    "plt.plot([0, 1], [base_rate, base_rate]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(Xtrain.index).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
